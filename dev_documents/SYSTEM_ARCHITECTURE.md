# System Architecture: Autonomous Development Environment (AC-CDD)

## 1. Core Philosophy

The Autonomous Development Environment (AC-CDD) is an AI-native framework designed to automate the software development lifecycle, from high-level requirements to deployment-ready code. Its philosophy is rooted in **Cycle-Based Contract-Driven Development**, ensuring that every piece of generated code is meticulously planned, rigorously audited, and verified against clear specifications.

The system is architected as a four-layer model, promoting separation of concerns and modularity. This structure ensures that the system is extensible, maintainable, and robust.

## 2. Architectural Layers

The four layers of the AC-CDD architecture are:

1.  **Orchestration Layer**: The brain of the system, managing the overall workflow and state.
2.  **Agent Layer**: The workforce, consisting of specialized AI agents that perform specific tasks.
3.  **Tooling Layer**: The utility belt, providing essential services and integrations.
4.  **Sandbox Execution Layer**: The secure environment where code is executed and tested.

---

### 2.1. Orchestration Layer

This layer is responsible for coordinating the entire development process. It sequences tasks, manages state, and facilitates communication between the different layers.

*   **Core Component**: `LangGraph State Machine`
*   **Description**: A stateful graph that defines the development workflow. Each node in the graph represents a specific state or action (e.g., 'Awaiting Architecture', 'Coding', 'Auditing', 'Testing'). The edges represent transitions based on the outcome of the actions.
*   **Key Responsibilities**:
    *   Managing the lifecycle of a development session (`gen-cycles`, `run-cycle`, `finalize-session`).
    *   Persisting and resuming the development state (e.g., using `.ac_cdd_session.json`).
    *   Coordinating the handover of tasks between different agents (e.g., from Architect to Coder, from Coder to Auditor).
    *   Implementing the iterative audit-fix loop, ensuring code quality meets the defined standards.

### 2.2. Agent Layer

This layer comprises a committee of specialized Large Language Model (LLM) agents, each with a distinct role. This separation of duties ensures that the right "mind" is used for each task, optimizing for both intelligence and efficiency.

*   **Agents**:
    1.  **Architect Agent (Jules)**:
        *   **Responsibility**: Translates raw user requirements (`ALL_SPEC.md`) into a formal `SYSTEM_ARCHITECTURE.md`, detailed `SPEC.md`, and actionable `UAT.md` for each development cycle.
        *   **Characteristics**: Utilizes a high-capability model with a long context window to understand the entire project scope.

    2.  **Coder Agent (Jules)**:
        *   **Responsibility**: Implements the features defined in a cycle's `SPEC.md` and `UAT.md`. Writes both the application code and the corresponding tests.
        *   **Characteristics**: Follows Test-Driven Development (TDD) principles. Operates in a "session" that can be resumed for fixing.

    3.  **Auditor Agent (LLMReviewer/Fast Model)**:
        *   **Responsibility**: Performs static analysis and code review on the code generated by the Coder Agent. It identifies bugs, style violations, and deviations from best practices. The system employs a committee of three independent auditors to ensure comprehensive coverage.
        *   **Characteristics**: Uses a fast, cost-effective model optimized for code analysis. It provides structured feedback that can be programmatically parsed.

    4.  **Fixer Agent (Jules)**:
        *   **Responsibility**: Takes the feedback from the Auditor Agent and makes the necessary corrections to the code. This is achieved by resuming the original Coder Agent's session with the audit report as additional context.
        *   **Characteristics**: The same high-capability model as the Coder, ensuring it understands the original intent while incorporating the required fixes.

    5.  **QA Analyst Agent (Fast Model)**:
        *   **Responsibility**: Evaluates the results of the automated tests against the `UAT.md`. It determines whether the implemented features meet the acceptance criteria.
        *   **Characteristics**: A model focused on logical reasoning and verification, comparing test logs to Gherkin-style behavior definitions.

### 2.3. Tooling Layer

This layer provides a suite of services and utilities that support the agents and the orchestrator.

*   **Core Components**:
    *   **CLI (`manage.py`)**: The main user interface for interacting with the AC-CDD. It exposes commands like `init`, `gen-cycles`, and `run-cycle`.
    *   **Git Manager**: A wrapper around `git` and `gh` CLI tools to automate all version control operations, including branching, committing, creating pull requests, and merging.
    *   **File Manager**: Handles all file I/O operations, ensuring that agents can read from and write to the correct locations in the project structure.
    *   **Configuration Manager**: Loads and provides access to settings from `.env` and `ac_cdd_config.py`, such as API keys and model names.

### 2.4. Sandbox Execution Layer

This layer provides a secure, isolated, and ephemeral environment for all dynamic operations, such as running tests and executing code. This is a critical security feature, preventing untrusted AI-generated code from accessing the local file system or network.

*   **Core Component**: `E2B Sandbox`
*   **Description**: A secure, cloud-based environment that mirrors the project's file structure.
*   **Key Responsibilities**:
    *   Installing all project dependencies in a clean environment.
    *   Running the test suite (`pytest`) against the AI-generated code.
    *   Providing a secure execution environment for any other required commands.
    *   Synchronizing the results (e.g., test logs, modified files) back to the local machine for the Orchestration layer to process.

## 3. Data Flow and Workflow

The typical workflow proceeds as follows:

1.  **Initialization**: The user runs `uv run manage.py init` and defines their requirements in `dev_documents/ALL_SPEC.md`.
2.  **Architecture Generation**: The user runs `uv run manage.py gen-cycles`.
    *   The **Orchestrator** invokes the **Architect Agent**.
    *   The **Architect Agent** reads `ALL_SPEC.md` and generates `SYSTEM_ARCHITECTURE.md`, `CYCLE{xx}/SPEC.md`, and `CYCLE{xx}/UAT.md`.
    *   The **Git Manager** commits these artifacts to a new architecture branch.
3.  **Development Cycle**: The user runs `uv run manage.py run-cycle --id 01`.
    *   The **Orchestrator** creates a new feature branch for the cycle.
    *   The **Orchestrator** invokes the **Coder Agent**, providing the relevant `SPEC.md` and `UAT.md`.
    *   The **Coder Agent** writes code and tests.
    *   The **Orchestrator** sends the generated code to the **Sandbox Execution Layer**.
    *   The **Sandbox** runs the tests. The results are sent back.
    *   The **QA Analyst Agent** evaluates the test results against the `UAT.md`.
    *   If tests pass, the **Orchestrator** initiates the audit loop.
    *   The **Auditor Agent** reviews the code and generates a report.
    *   If issues are found, the **Orchestrator** invokes the **Fixer Agent** with the code and the audit report. The loop repeats (code -> test -> audit -> fix) for a total of 6 iterations.
    *   Once all quality gates are passed, the **Git Manager** commits the final code to the cycle's feature branch and merges it into the main session integration branch.
4.  **Finalization**: The user runs `uv run manage.py finalize-session`.
    *   The **Git Manager** creates a final Pull Request from the session integration branch to the `main` branch for a final human review.
