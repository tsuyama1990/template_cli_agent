# UAT.md - Cycle 04: Auditor and QA Agent Integration

## 1. Test Scenarios

This document outlines the User Acceptance Testing (UAT) scenarios for Cycle 04. The primary focus of this cycle is the successful integration of the QA Analyst and Auditor agents into the `run-cycle` workflow, transforming it into a quality-gated process. These tests are designed to verify, from a user's perspective, that the new automated testing and code auditing quality gates are functioning correctly. The scenarios will validate that the workflow responds appropriately to both positive and negative outcomes from these gatesâ€”either proceeding on success or halting and providing clear, actionable feedback on failure. The successful completion of these tests will provide confidence that the system can reliably enforce code quality and correctness.

| Scenario ID | Description                                                              | Priority |
|-------------|--------------------------------------------------------------------------|----------|
| UAT-04-001  | Golden Path: Code Successfully Passes Both Testing and Auditing Gates      | High     |
| UAT-04-002  | Workflow Correctly Halts Immediately Upon a Test Failure                 | High     |
| UAT-04-003  | Workflow Correctly Halts After Passing Tests but Failing an Audit          | High     |
| UAT-04-004  | User Receives a Clear and Actionable Test Failure Report                 | High     |
| UAT-04-005  | User Receives a Clear and Actionable Audit Report                        | High     |

**Scenario Details:**

**UAT-04-001: Golden Path: Code Successfully Passes Both Testing and Auditing Gates**
This is the quintessential "happy path" scenario for this cycle. It validates the entire, enhanced workflow from start to finish under ideal conditions. The test ensures that when the Coder Agent produces code that is both functionally flawless (as verified by the QA Agent) and meets all quality and security standards (as verified by the Auditor Agent), the process completes successfully. This means the code is synchronized back to the user's local machine, representing a finished piece of work. This scenario is of the highest priority as it confirms that the quality gates do not block correctly written code and that the entire integrated pipeline is functional.

**UAT-04-002: Workflow Correctly Halts Immediately Upon a Test Failure**
This scenario tests the effectiveness of the QA Analyst Agent as the first critical quality gate. Software that is not functionally correct should not proceed further in the pipeline. This test verifies that if the code generated by the Coder Agent contains a bug that causes a test to fail, the `run-cycle` workflow stops immediately after the `TESTING` phase. It is crucial that the system does not waste time and resources by proceeding to the auditing phase with code that is already known to be broken. This test also ensures that this buggy code is *not* synchronized back to the user's local machine, thereby protecting the user's workspace from being contaminated by non-working code.

**UAT-04-003: Workflow Correctly Halts After Passing Tests but Failing an Audit**
This scenario validates the Auditor Agent as the second, equally important quality gate. It addresses the case where code might be functionally correct (i.e., it passes all tests) but is still of poor quality. This could be due to a security vulnerability, a significant performance issue, or a blatant violation of coding standards. This test ensures that even if the code passes the `TESTING` phase, if the Auditor Agent flags a critical issue, the workflow halts. This is critical for enforcing non-functional requirements and ensuring that the final output is not just code that "works," but code that is secure, robust, and maintainable.

**UAT-04-004: User Receives a Clear and Actionable Test Failure Report**
This scenario focuses on the user experience in a failure condition. It is not sufficient for the workflow to simply stop when a test fails; it must provide the user with the information they need to understand the problem. This test verifies that when the workflow halts due to a test failure, the system prints the full, captured output from the test runner (e.g., `pytest`) to the console. The user should be able to clearly see which tests failed, the assertion errors, and the traceback, which is essential for debugging.

**UAT-04-005: User Receives a Clear and Actionable Audit Report**
Similar to the previous scenario, this test ensures that the output of a failed audit is communicated effectively to the user. When the Auditor Agent finds issues and halts the workflow, it must present its findings in a human-readable and structured format. This test verifies that the final console output includes a clear report listing each identified issue, including crucial context like the file path, the line number, a description of the problem, and its assigned severity. This actionable report is vital for enabling the user (or, in the next cycle, the automated fixing agent) to address the identified quality problems.

## 2. Behavior Definitions

**Scenario: UAT-04-001 - Golden Path: Code Successfully Passes Both Testing and Auditing Gates**

*   **GIVEN** I am a user with a valid `.env` file and a `SPEC.md` for the current cycle.
*   **AND** the Coder Agent is configured to generate code that is 100% functionally correct according to the project's test suite.
*   **AND** the generated code is of high quality and contains no security flaws or major style violations.
*   **WHEN** I execute the `run-cycle` command for this cycle.
*   **THEN** the console output should clearly show the workflow progressing through its stages in order: `CODING`, then `TESTING`, then `AUDITING`.
*   **AND** the status message for the `TESTING` phase should indicate success, such as "All 3 tests passed."
*   **AND** the status message for the `AUDITING` phase should indicate success, such as "Audit complete. No critical issues found."
*   **AND** the command should complete with a final success message.
*   **AND** the newly generated, fully validated code from the sandbox must be synchronized to my local `src/` directory.

**Scenario: UAT-04-002 - Workflow Correctly Halts Immediately Upon a Test Failure**

*   **GIVEN** I am a user with a valid setup.
*   **AND** the Coder Agent is configured to generate code that contains a logical bug.
*   **AND** the project's test suite contains a test that will definitively fail because of this bug.
*   **WHEN** I execute the `run-cycle` command.
*   **THEN** the workflow should proceed through the `CODING` phase and into the `TESTING` phase.
*   **AND** during the `TESTING` phase, the system should detect the test failure.
*   **AND** the command must terminate immediately after the `TESTING` phase reports the failure.
*   **AND** the console output must **not** show any status messages indicating that the `AUDITING` phase has started.
*   **AND** the state of my local `src/` directory must be unchanged from before I ran the command; the buggy code must not be synchronized back.

**Scenario: UAT-04-003 - Workflow Correctly Halts After Passing Tests but Failing an Audit**

*   **GIVEN** I am a user with a valid setup.
*   **AND** the Coder Agent is configured to generate code that is functionally correct and passes all tests.
*   **AND** however, the generated code contains a critical security vulnerability (e.g., a hardcoded password or use of a dangerous function like `pickle`).
*   **WHEN** I execute the `run-cycle` command.
*   **THEN** the workflow should successfully complete the `CODING` and `TESTING` phases.
*   **AND** the workflow should then proceed to the `AUDITING` phase.
*   **AND** during the `AUDITING` phase, the system should detect the critical vulnerability.
*   **AND** the command must terminate immediately after the `AUDITING` phase reports the failure.
*   **AND** the state of my local `src/` directory must be unchanged, as the insecure code must not be synchronized back.

**Scenario: UAT-04-004 - User Receives a Clear and Actionable Test Failure Report**

*   **GIVEN** a `run-cycle` command has terminated due to a test failure, as described in scenario UAT-04-002.
*   **WHEN** the command exits.
*   **THEN** the final output in my console must include a clearly demarcated section with a title like "--- TEST FAILURE REPORT ---".
*   **AND** this section must contain the complete, unabridged `stdout` and `stderr` output from the test runner command (e.g., `pytest`) that was executed in the sandbox.
*   **AND** this output must be formatted correctly, allowing me to easily read the traceback and assertion error to understand exactly which test failed and why.

**Scenario: UAT-04-005 - User Receives a Clear and Actionable Audit Report**

*   **GIVEN** a `run-cycle` command has terminated due to an audit failure, as described in scenario UAT-04-003.
*   **WHEN** the command exits.
*   **THEN** the final output in my console must include a clearly demarcated section with a title like "--- CODE AUDIT REPORT ---".
*   **AND** this section must contain a structured summary of the issues that the Auditor Agent discovered.
*   **AND** for each issue, the report must clearly list the following details: the relative **File Path** (e.g., `src/core/auth.py`), the **Line Number** where the issue was found, the **Severity** of the issue (e.g., "Critical"), and a concise **Description** of the problem (e.g., "Hardcoded secret key found. API keys should be loaded from environment variables.").
