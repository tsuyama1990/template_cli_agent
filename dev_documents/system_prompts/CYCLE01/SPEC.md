# Specification: CYCLE01 - Core Engine & Workflow Foundation

## 1. Summary

This foundational cycle, CYCLE01, marks the inception of the MLIP-AutoPipe project. The primary objective is to establish a robust and scalable software architecture that will serve as the bedrock for all subsequent development. This cycle is not focused on delivering advanced scientific features but on creating the essential plumbing and core components required to connect a DFT calculation engine with an MLIP training engine. The scope is tightly controlled to ensure a high-quality foundation. We will implement the fundamental project structure using modern Python packaging standards (`pyproject.toml`, `uv`), define the central data structures for configuration using Pydantic, and create a crucial database abstraction layer to handle data persistence.

The key deliverables for this cycle are a simplified, non-automated `LabelingEngine` and a `TrainingEngine`. The `LabelingEngine` will be capable of taking a single, pre-defined atomic structure and executing a Quantum Espresso calculation to obtain its energy, forces, and stress. It will not yet have sophisticated error handling or parameter automation. The `TrainingEngine`, in parallel, will be capable of ingesting a small, manually curated dataset (which could be generated by the `LabelingEngine`) and training a basic Atomic Cluster Expansion (ACE) potential. The critical success factor for this cycle is the successful integration of these components through a rudimentary `WorkflowOrchestrator` and the `AseDBWrapper`. By the end of this cycle, we will have a demonstrable, albeit manual, workflow: a developer can place an atomic structure in the database, trigger the labelling engine to perform a DFT calculation, and then trigger the training engine to produce a valid MLIP model. This proves the viability of the core concept before introducing the complexity of automation and intelligent sampling in later cycles.

## 2. System Architecture

The architecture for CYCLE01 establishes the blueprint for the entire application. It focuses on creating the essential files and directory structures that will house the core logic.

**File Structure (CYCLE01 Focus):**

The files and directories to be created or modified in this cycle are marked in **bold**.

```
mlip-autopipec/
├── **pyproject.toml**
├── **uv.lock**
├── **src/**
│   └── **mlip_autopipec/**
│       ├── **__init__.py**
│       ├── **cli.py**              # Basic CLI structure
│       ├── **workflow.py**         # Rudimentary orchestrator
│       ├── **config.py**           # Pydantic models
│       ├── **database.py**         # ASE Database wrapper
│       └── **modules/**
│           ├── **__init__.py**
│           ├── structure_generator.py # Stub file
│           ├── explorer_sampler.py    # Stub file
│           ├── **labeling_engine.py**     # Module C (simplified)
│           ├── **training_engine.py**     # Module D (simplified)
│           └── simulation_engine.py   # Stub file
└── **tests/**
    ├── **conftest.py**
    ├── **unit/**
    │   ├── **test_config.py**
    │   └── **test_database.py**
    └── **integration/**
        └── **test_workflow.py**
```

**Component Breakdown:**

*   **`pyproject.toml`**: This file will be created to manage all project metadata, dependencies, and tool configurations. It will define the project as an installable package named `mlip_autopipec`. Dependencies will include `click` for the CLI, `pydantic` for configuration, `ase` for atomic structure manipulation and database access, `numpy` for numerical data, and the necessary libraries for the ACE model (`pacemaker-python`).
*   **`src/mlip_autopipec/`**: The main source directory for the installable package.
*   **`config.py`**: This file will contain the initial Pydantic models that define the structure of the project's configuration. In this cycle, it will define `DFTComputeConfig` (with fields for the QE command, pseudopotentials, basic cutoffs) and `MLIPTrainingConfig` (specifying the model type as ACE and basic parameters).
*   **`database.py`**: This will house the `AseDBWrapper` class. This class will abstract the `ase.db.connect` functionality, providing clear, intention-revealing methods such as `add_atoms`, `get_atoms_by_id`, `update_labels`, and `get_all_labeled_atoms`. This isolates all database interactions into a single, easily mockable component.
*   **`labeling_engine.py`**: A simplified `LabelingEngine` class will be implemented. It will take a configuration object and a database wrapper during initialisation. Its primary method, `label_structure(id)`, will fetch a specific `Atoms` object from the database, construct a Quantum Espresso input file using ASE's file I/O, execute `pw.x` via a `subprocess.run` call, parse the output for energy/forces/stress, and use the database wrapper to persist these labels. Error handling will be minimal at this stage.
*   **`training_engine.py`**: A basic `TrainingEngine` class. Its main method, `train()`, will query the database wrapper for all available labelled data, convert it into the format expected by the ACE training library, execute the training process, and save the resulting potential model to a file.
*   **`workflow.py`**: A `WorkflowOrchestrator` class will be defined. For CYCLE01, it will have distinct methods like `run_labeling_for_id(id)` and `run_training()` that can be called sequentially from the CLI. This orchestrator will be responsible for initialising the engines and the database wrapper.
*   **`cli.py`**: A rudimentary CLI using `click`. It will provide two commands: `cdd label --id <ID>` and `cdd train`. These commands will instantiate the `WorkflowOrchestrator` and call the respective methods, providing a manual way to step through the core workflow.

## 3. Design Architecture

The design of CYCLE01 is centered on establishing clear data contracts and responsibilities using Pydantic models. This schema-first approach ensures that all components communicate with well-defined, validated data structures, preventing a wide class of runtime errors.

*   **`config.py` - Pydantic Schemas:**
    *   `DFTInputConfig`: A model representing the *inputs* for a QE calculation. It will include fields for `pseudopotentials` (as a dictionary mapping element to filename), `kpoints` (a tuple), `ecutwfc` (an integer), and the calculation `control` parameters as a nested dictionary. This model enforces that a calculation cannot be defined without these critical parameters.
    *   `DFTResult`: A model to store the *outputs* of a QE calculation. It will contain fields for `energy` (float), `forces` (a `numpy.ndarray` which will be validated by a custom Pydantic type), and `stress` (a `numpy.ndarray`). This ensures that consumers of DFT results always receive a complete and type-correct data structure.
    *   `MLIPTrainingConfig`: A model defining the training job, specifying `model_type` (e.g., an Enum with "ACE" as the only member for now), `r_cut` (float), and `loss_weights` (a dictionary mapping "energy" to a float, etc.).
    *   **Producers/Consumers:** The `LabelingEngine` is the producer of `DFTResult` objects. The `TrainingEngine` is a consumer of many `DFTResult` objects. The `WorkflowOrchestrator` is the primary consumer of the configuration models.
    *   **Versioning:** Initially, all models are version 1.0. While no extensibility is built in yet, the use of Pydantic provides a clear path for future versioning by adding new optional fields or using versioned model namespaces.

*   **`database.py` - `AseDBWrapper` Data Flow:**
    *   The `AseDBWrapper` acts as a crucial data intermediary. The `ase.db` format stores arbitrary key-value pairs (`kvp`). We will establish a strict contract on these `kvp`s.
    *   **`state` key**: A mandatory key will be used to track the status of each entry. The state will be one of "unlabeled", "labeling_in_progress", "labeled", or "labeling_failed".
    *   **`dft_result` key**: For a 'labeled' entry, the entire `DFTResult` Pydantic model will be serialised to a JSON string and stored in a single key-value pair named `dft_result`. This encapsulates all DFT output cleanly, avoiding pollution of the top-level key-value space. The wrapper's `update_labels` method will be responsible for this serialization, and its `get_...` methods will handle deserialization and validation, returning a full `DFTResult` object.
    *   **Invariants:** The wrapper will enforce the invariant that an entry with `state='labeled'` *must* have a valid, deserializable `dft_result` key.

## 4. Implementation Approach

The implementation will proceed in a logical, dependency-first order.

1.  **Project Setup:** The first step is to create the `pyproject.toml` file. This involves defining the project name (`mlip_autopipec`), version (`0.1.0`), and adding the initial list of dependencies (`click`, `pydantic`, `ase`, `numpy`, `pacemaker-python`, `uv`). After this, `uv pip install -e .` will be run to create an editable install of the package.
2.  **Pydantic Models:** The `config.py` file will be created, and the core Pydantic models (`DFTInputConfig`, `DFTResult`, `MLIPTrainingConfig`) will be implemented. This is done first as these models are the data contracts that other components will depend on. Custom validators, especially for the NumPy array types, will be included.
3.  **Database Wrapper:** Next, the `database.py` file will be created. The `AseDBWrapper` class will be implemented, using an in-memory SQLite database for initial development. The methods (`add_atoms`, `update_labels`, etc.) will be written, including the JSON serialization/deserialization logic for the `DFTResult` model.
4.  **Labeling Engine:** The `labeling_engine.py` file will be created. The `LabelingEngine` class will be implemented. A simple, fixed `Atoms` object (e.g., a water molecule) will be used for the initial implementation. The logic will focus on correctly using ASE to generate a QE input file, calling `pw.x` with `subprocess.run`, parsing the output text file to extract the required numbers, populating a `DFTResult` model, and calling the `AseDBWrapper` to store it.
5.  **Training Engine:** The `training_engine.py` file will be created. The `TrainingEngine` class will be implemented. Its `train` method will call the `AseDBWrapper`'s `get_all_labeled_atoms` method. It will then contain the necessary boilerplate code to transform the list of `Atoms` objects and their associated `DFTResult` data into the data format expected by the `pacemaker` library and run its training function.
6.  **Orchestrator and CLI:** Finally, the `workflow.py` and `cli.py` files will be created. The `WorkflowOrchestrator` will be a simple class that initialises the other components. The `click` CLI will provide the two commands to instantiate the orchestrator and trigger the labeling and training processes. This will tie everything together and provide a tangible way to execute the cycle's functionality.

## 5. Test Strategy

Testing in CYCLE01 is critical to ensure the foundation is sound. We will use a combination of unit and integration tests, with a heavy emphasis on mocking external dependencies.

**Unit Testing Approach (Min 300 words):**
The unit tests will be designed to verify the correctness of each component in complete isolation.

*   **`test_config.py`**: This will contain tests for the Pydantic models. We will test validation logic thoroughly. For example, we will create a `DFTResult` model with forces that are not a NumPy array and assert that a `ValidationError` is raised. We will test that a `DFTInputConfig` without a `kpoints` value also raises an error. We will also test successful cases, ensuring that valid data is correctly parsed and stored. The JSON serialization and deserialization of the models, particularly the one containing NumPy arrays, will be explicitly tested to ensure it's round-trip safe.
*   **`test_database.py`**: The `AseDBWrapper` will be tested against a temporary, in-memory SQLite database created and torn down for each test function. We will write tests for each method. For example, `test_add_atoms` will add an `Atoms` object and then use a direct `ase.db` connection to assert that the row was created with the correct initial `state='unlabeled'`. The `test_update_labels` test will be crucial; it will add a raw atom, then call `update_labels` with a `DFTResult` object, and finally assert that the row's `state` is now 'labeled' and the `dft_result` key contains the correct JSON representation of the `DFTResult` object.

**Integration Testing Approach (Min 300 words):**
The integration tests will verify that the core components collaborate correctly. The key philosophy here is to mock any external processes, specifically the Quantum Espresso binary itself.

*   **`test_workflow.py`**: This file will house the main integration test for the cycle. We will create a test function, for instance, `test_label_and_train_workflow`.
    1.  **Mocking:** We will use `pytest-mock`'s `mocker` fixture to patch `subprocess.run`. The mock will be configured so that when it is called with a command corresponding to `pw.x`, it does not execute anything. Instead, it will create a dummy QE output file in a temporary directory, with pre-defined, hardcoded energy, force, and stress values.
    2.  **Execution:** The test will instantiate the `WorkflowOrchestrator`. It will first create a test database and add a sample `Atoms` object to it, getting its ID. It will then call the orchestrator's `run_labeling_for_id(id)` method.
    3.  **Assertion (Labeling):** We will assert that `subprocess.run` was called exactly once with the expected command-line arguments. Then, we will connect to the test database and verify that the corresponding atom row has been updated to `state='labeled'` and contains the correctly parsed `DFTResult`.
    4.  **Execution (Training):** Next, the test will call the orchestrator's `run_training()` method. We will mock the `pacemaker.fit` function itself to avoid actually training a model, which would be slow.
    5.  **Assertion (Training):** We will assert that the mock `pacemaker.fit` function was called with data that correctly corresponds to the `DFTResult` we placed in the database during the labeling step. This verifies that the `TrainingEngine` correctly queries, deserializes, and transforms the data for the learning algorithm.
