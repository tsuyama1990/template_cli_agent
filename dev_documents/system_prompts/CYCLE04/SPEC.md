# Specification: CYCLE04 - Surrogate-Based Exploration (MACE Integration)

## 1. Summary

CYCLE04 introduces a transformative capability into the MLIP-AutoPipe pipeline: high-speed, surrogate-based exploration. The primary goal of this cycle is to implement the first half of `Module B: Explorer & Sampler` by integrating a pre-trained, universal machine learning potential. We will standardize on MACE (Materials ACE), specifically the MACE-MP-0 model, which has been trained on the vast Materials Project database. This integration will allow the pipeline to perform large-scale Molecular Dynamics (MD) simulations orders of magnitude faster than would be possible with DFT, enabling a broad exploration of the material's potential energy surface at a negligible computational cost.

The scope of this cycle is to build the `Explorer` component. This component will take the initial, static structures generated in CYCLE03 and use them as starting points for extensive MD simulations driven by the MACE potential. The system will run these simulations under various thermodynamic conditions (e.g., the different temperatures defined in the `FullConfig`). The output of this cycle will be a massive amount of trajectory data—potentially millions of atomic configurations—that broadly samples the phase space. This vast, unexplored territory will be the raw material for the intelligent sampling to be implemented in the next cycle. The successful completion of this cycle will mean the pipeline is no longer limited to the immediate vicinity of the initial structures but can now proactively explore diverse structural and thermal environments before committing to expensive DFT calculations.

## 2. System Architecture

This cycle focuses on implementing the `Explorer` part of the `explorer_sampler.py` module. It requires integrating the MACE library and running PyTorch-based MD simulations.

**File Structure (CYCLE04 Focus):**

Files to be created or modified are in **bold**.

```
mlip-autopipec/
├── pyproject.toml
├── uv.lock
├── src/
│   └── mlip_autopipec/
│       ├── __init__.py
│       ├── **cli.py**              # Add option to control exploration
│       ├── **workflow.py**         # Orchestrator calls the Explorer
│       ├── **config.py**           # Add config options for Explorer (MD steps, etc.)
│       ├── database.py
│       └── modules/
│           ├── __init__.py
│           ├── structure_generator.py
│           ├── **explorer_sampler.py** # Explorer implementation
│           ├── labeling_engine.py
│           ├── training_engine.py
│           └── simulation_engine.py
└── tests/
    ├── conftest.py
    ├── unit/
    │   ├── test_config_expander.py
    │   └── **test_explorer.py**      # New test file
    └── integration/
        └── test_workflow.py
```

**Component Breakdown:**

*   **`pyproject.toml`**: The dependencies for MACE (`mace-torch`) and its requirements (e.g., `torch`) will be added to the project.
*   **`config.py`**: The `SimulationConfig` Pydantic model will be extended with a new section for the explorer.
    *   `ExplorerConfig`: A new model will contain fields like `surrogate_model: str` (defaulting to `"mace_mp"`), `md_steps_per_structure: int` (e.g., default 10,000), and `thermostat: str` (e.g., "NVT").
*   **`modules/explorer_sampler.py`**: This file will now house the `Explorer` class.
    *   The `Explorer` class will be initialized with the `ExplorerConfig` and a reference to the `AseDBWrapper`.
    *   Its main public method, `explore()`, will be the entry point.
    *   The `explore` method will query the database for the initial structures generated by `Module A`. For each structure, it will launch a series of MD simulations, one for each temperature in `config.simulation.temperature_steps`.
    *   A private method, `_run_mace_md(atoms, temperature)`, will encapsulate the logic for a single MD run. This method will load the pre-trained MACE model, attach it to the `ase.Atoms` object as a calculator, and use ASE's MD integration (e.g., `Langevin` or `NPT`) to run the simulation.
    *   The trajectories (atomic positions over time) will be collected. For now, they will be stored in memory or temporary files, awaiting the sampler implementation in the next cycle.
*   **`workflow.py`**: The `WorkflowOrchestrator`'s `run()` method will be updated. After the `StructureGenerator` (if needed), it will now instantiate and call the `Explorer`'s `explore()` method. This step now sits squarely between initial structure generation and DFT labelling.
*   **`tests/unit/test_explorer.py`**: A new test file dedicated to unit-testing the `Explorer` class. These tests will mock the MACE model itself to avoid downloading the model and running real, time-consuming calculations.

## 3. Design Architecture

The design of the `Explorer` focuses on creating a robust interface with the external MACE library and ASE's dynamics functionality.

*   **`Explorer` Class Design:**
    *   **Model Loading:** The `Explorer` will contain logic to automatically download and cache the pre-trained MACE-MP-0 model on its first run. This avoids requiring the user to manually download it. It will use a standardized location for caching. GPU support will be handled by checking for CUDA availability (`torch.cuda.is_available()`) and setting the device accordingly.
    *   **MD Simulation Loop:** The `_run_mace_md` method will be the core of the scientific logic. It will demonstrate best practices for setting up ASE MD simulations:
        1.  Create the `Atoms` object.
        2.  Load the MACE calculator and set `atoms.calc = mace_calculator`.
        3.  Initialize a dynamics object, e.g., `dyn = Langevin(atoms, timestep=2*units.fs, temperature_K=temperature, friction=0.02)`.
        4.  Attach a trajectory logger, `dyn.attach(trajectory.observe, interval=100)`.
        5.  Run the dynamics: `dyn.run(steps=config.explorer.md_steps_per_structure)`.
    *   **Data Handling:** In this cycle, the primary concern is generating the data. The `explore` method will return a large list of all the `ase.Atoms` objects collected from all the trajectory runs. This in-memory list will be the input for the `Sampler` in the next cycle. (Note: For very large explorations, this will be revisited and potentially replaced with a file-based or database-streaming approach to manage memory).

*   **Pydantic Schema Interaction:**
    *   The `Explorer` is a direct consumer of the new `ExplorerConfig` section of the `FullConfig`. It uses these parameters to control the length and conditions of the MD simulations.
    *   It also consumes the `SimulationConfig.temperature_steps` to know which temperatures to simulate at.

## 4. Implementation Approach

The implementation will be methodical, focusing on getting the external MACE library integrated and tested before wiring it into the main workflow.

1.  **Dependency and Configuration:** First, add `mace-torch` to `pyproject.toml`. Then, update `config.py` to include the new `ExplorerConfig` Pydantic model. Add the new fields to the `FullConfig`.
2.  **TDD for the Explorer:** Create the `test_explorer.py` file. Write the first and most important test: `test_run_single_md_simulation`.
    *   **Mocking Strategy:** This test will heavily mock the MACE and ASE components. We will use `pytest-mock`'s `mocker` to patch the `mace.models.MACE.load_calculator` function. The mock will return a dummy calculator object. We will also mock ASE's `Langevin` dynamics class to avoid running a real simulation loop.
    *   The test will instantiate the `Explorer` with a test configuration.
    *   It will call the private method `_run_mace_md`.
    *   The assertions will focus on the setup: Was `mace.models.MACE.load_calculator` called with the correct model name and device? Was the `Langevin` dynamics object initialized with the correct `atoms` object and `temperature`? Was its `run()` method called with the correct number of steps from the config?
3.  **Implement the Explorer:** Implement the `_run_mace_md` method to make the unit test pass. This includes the logic for loading the MACE model, setting up the ASE calculator, and configuring the `Langevin` dynamics object.
4.  **Implement the Main `explore` Loop:** Implement the public `explore()` method. This method will iterate through the initial structures and the configured temperatures, calling `_run_mace_md` for each combination. It will collect all the resulting trajectory frames into a single large list.
5.  **Workflow Integration:** Modify the `WorkflowOrchestrator` in `workflow.py`. Add a call to `explorer.explore()` after the structure generation step. The orchestrator will hold the returned list of trajectory frames in memory for now.
6.  **Integration Test:** Update the integration test in `test_workflow.py`.
    *   The test will mock the `Explorer` class itself.
    *   After the `StructureGenerator` runs, the test will assert that the mocked `Explorer`'s `explore()` method is called.
    *   The mock `explore()` method will be configured to return a small, fixed list of a few `ase.Atoms` objects, simulating the result of a trajectory.
    *   The test will then need to be updated to reflect a temporary change: for now, these explored structures will be passed to the (mocked) `LabelingEngine`. This verifies the data handoff, even though we know this is inefficient and will be replaced by the `Sampler` in the next cycle.

## 5. Test Strategy

Testing in this cycle is about ensuring the correct integration of a complex external library (MACE) and managing the data it produces.

**Unit Testing Approach (Min 300 words):**
The unit tests in `test_explorer.py` will completely isolate the `Explorer` from the actual MACE model and ASE's time-consuming dynamics.

*   **`test_mace_model_loading`**: A dedicated test will verify the model loading logic. It will mock `torch.cuda.is_available` to return `True` and `False` in two separate runs, asserting that the device passed to the mocked `mace.models.MACE.load_calculator` is `'cuda'` and `'cpu'`, respectively. It will also confirm that the model caching logic is called correctly.
*   **`test_md_simulation_setup`**: This test, as described in the implementation section, will be the core of the unit tests. It will confirm, via mocking, that the `Explorer` correctly configures the ASE dynamics object based on the Pydantic configuration. It will check the `timestep`, `temperature`, `friction` parameter of the `Langevin` mock, and the `steps` passed to the `run` mock. This ensures that the configuration is being correctly translated into simulation parameters.
*   **`test_explore_loop_logic`**: This test will verify the main `explore()` method's looping behavior. Given 2 initial structures and 3 temperatures, it will assert that the mocked `_run_mace_md` method is called exactly 6 times with the correct combinations of atoms and temperatures.

**Integration Testing Approach (Min 300 words):**
The integration test will ensure that the data produced by the exploration phase is correctly injected into the main pipeline workflow.

*   **`test_workflow_with_exploration_step`**: This test in `test_workflow.py` will provide a holistic check.
    1.  **Setup**: It will start with a minimal `input.yaml` and an empty database.
    2.  **Mocking**: It will mock the `Explorer` class, specifically the `explore` method. We do not want to run a real MACE simulation in an integration test. The mock will be configured to `return [atoms1, atoms2, atoms3]`, where these are predefined `ase.Atoms` objects. `subprocess.run` for QE will also be mocked as before.
    3.  **Execution**: The CLI runner will execute the workflow.
    4.  **Assertions**:
        *   The test will first assert that the `StructureGenerator` runs and populates the database.
        *   Then, it will assert that the mocked `Explorer.explore()` method was called.
        *   The crucial new assertion is to check what happens with the data returned by the mock explorer. In this cycle, the orchestrator's logic will be temporarily to treat these explored structures as candidates for labelling. The test will assert that the `AseDBWrapper`'s `add_atoms` method is called for each of the atoms returned by the mock explorer.
        *   Finally, it will assert that the mocked `LabelingEngine` is subsequently called for these new, explored structures. This confirms the data flow: `Generator -> DB -> Explorer -> (Memory) -> DB -> Labeler`, setting the stage perfectly for the `Sampler` to be inserted in the next cycle.
