# Cycle 01 Specification: Core Engine - DFT Labelling and MLIP Training

## 1. Summary

This document provides the detailed technical specifications for Cycle 01 of the MLIP-AutoPipe project. The primary objective of this foundational cycle is to construct the core computational engine of the pipeline. This involves developing the two most critical modules: the **Labelling Engine**, responsible for performing automated, high-precision Density Functional Theory (DFT) calculations using Quantum Espresso, and the **Training Engine**, responsible for training a Machine Learning Interatomic Potential (MLIP) based on the data generated by the Labelling Engine. This cycle will establish the fundamental workflow of taking a given atomic structure, calculating its physical properties (energy, forces, stress), and using this data to train a preliminary MLIP. The successful completion of this cycle will yield a functional, command-line-driven workflow capable of producing a basic MLIP for a given small dataset, thereby validating the fundamental components of our automated materials science pipeline.

The scope of this cycle is intentionally constrained to focus on the most critical components. It does not include the automated structure generation that will be introduced in Cycle 02, nor the sophisticated active learning loop planned for Cycle 04. The input for this cycle will be a manually provided set of atomic structures in a standard format (e.g., CIF or POSCAR), which will be loaded into a database for processing. This deliberate focus allows us to rigorously test the core functionalities of DFT automation and MLIP training in a controlled environment. Key deliverables for this cycle are a robust Python wrapper for the Quantum Espresso `pw.x` executable, a Python-based training script for the Atomic Cluster Expansion (ACE) model, and a custom database interface using the Atomic Simulation Environment (ASE) for data persistence and workflow management. Furthermore, the implementation will feature the "Delta Learning" approach from the outset. This technique, where the model learns the difference between a simple physical potential and the true DFT energy surface, is crucial for ensuring the physical realism and robustness of the final MLIP. This cycle lays the essential groundwork upon which all subsequent automation and intelligence will be built, ensuring that the core of the system is reliable, accurate, and efficient before more complex functionalities are added.

## 2. System Architecture

The architecture for Cycle 01 is a simplified, linear proof-of-concept of the final system, designed to validate the direct interaction between the Labelling and Training engines, mediated by a central database. This streamlined architecture allows for focused development and testing of the core data processing pipeline, from quantum mechanical calculations to machine learning model creation. Every component is designed with modularity and clear separation of concerns in mind, anticipating the more complex, cyclical workflow of later stages.

The process flow for this cycle is as follows:
1.  **Input:** The workflow is initiated with a set of user-provided atomic structures. These structures, representing the initial knowledge about the material, will be read by a simple script and loaded into the ASE Database. This manual step will be replaced by an automated generator in Cycle 02, but for now, it provides a controlled and reproducible starting point.
2.  **ASE Database (`AseDB` Wrapper):** A central data store, implemented as an SQLite database via the ASE library, will be established to manage the state of all atomic structures. For this cycle, its primary role is to act as a message-passing interface between the two engines. It will track the state of each structure, primarily whether it is "unlabelled" (newly imported) or "labelled" (its DFT properties have been successfully calculated). To ensure clean and maintainable code, all direct interactions with the database will be handled by a custom Python class, `AseDB`. This wrapper will provide a clean, high-level API for all database operations, abstracting away the underlying `ase.db` connection and query language. This design choice prevents direct database calls from cluttering the application logic and is critical for simplifying unit testing, as the entire database can be easily mocked.
3.  **Labelling Engine (Quantum Espresso Wrapper):** This module is the workhorse of the data generation process, interfacing with the external DFT code. It will be implemented as a Python class with a clear, single responsibility: to take unlabelled structures and calculate their physical properties. Its internal workflow is as follows:
    *   It queries the `AseDB` for any structures in the "unlabelled" state.
    *   For each structure, it generates a valid Quantum Espresso input file (`.in`). This is a non-trivial task that involves the automated, rule-based determination of key DFT parameters. For this cycle, it will implement logic to select appropriate plane-wave cutoffs and pseudopotentials based on the SSSP (Standard Solid State Pseudopotentials) protocol, a widely accepted standard for high-quality calculations.
    *   It executes the `pw.x` binary as an external process using Python's `subprocess` module. To maintain separation of concerns, the actual execution will be handled by a dedicated `ProcessRunner` abstraction, which will be injected into the engine.
    *   It then parses the resulting Quantum Espresso output file to extract the three key physical quantities: the total energy, the atomic forces, and the virial stress tensor.
    *   It performs robust error handling, detecting common SCF convergence failures by searching for specific error messages in the output file and logging them appropriately.
    *   Upon successful calculation, it populates the `AseDB` with the results and updates the structure's state to "labelled".
4.  **Training Engine (ACE Model Trainer):** This module is responsible for the creation of the MLIP itself. It will be implemented as a Python class that:
    *   Queries the `AseDB` to fetch all "labelled" structures and their corresponding data.
    *   Implements the "Delta Learning" strategy. This involves first calculating the energy and forces from a simple, physics-based baseline potential (e.g., Lennard-Jones). The engine will then compute the "delta" or residual (i.e., `delta_energy = dft_energy - baseline_energy`) for each data point.
    *   Prepares this dataset of residuals for the training framework, converting it into the required format.
    *   Uses the appropriate library calls to train an ACE model on this residual data. The ACE model is chosen for its systematic improvability and strong physical foundation.
    *   Saves the trained model to a file, which represents the final output of this cycle's workflow.
5.  **Orchestrator:** A simple Python script (`run_cycle_01.py`) will serve as the top-level orchestrator. It will be responsible for initialising the database and the engine classes with the correct configuration, and then invoking them in the correct sequence. It will first load the initial data into the database, then sequentially invoke the Labelling Engine for all structures, and finally, once all labelling is complete, invoke the Training Engine.

This architecture ensures a clear separation of concerns that is vital for building a complex scientific tool: the `AseDB` class handles data persistence, the `LabellingEngine` handles external process interaction and DFT-specific logic, and the `TrainingEngine` handles the machine learning aspect. This modularity allows each component to be developed, tested, and improved independently.

## 3. Design Architecture

The software design for Cycle 01 will adhere to modern Python development standards, emphasising modularity, full type hinting for code clarity and static analysis, and a design that prioritises testability from the ground up. The codebase will be organised into a clear package structure.

-   **`src/mlip_autopipec/data/database.py`:**
    -   **`AseDB` class:** This class will serve as the exclusive interface to the database, encapsulating all data persistence logic.
        -   `__init__(self, db_path: str)`: Connects to the ASE SQLite database file. The connection object will be a private instance variable.
        -   `add_atoms(self, atoms: list[ase.Atoms])`: Adds a list of ASE `Atoms` objects to the database. Each new entry will be given a default `state='unlabelled'` key-value pair.
        -   `get_atoms_by_state(self, state: str) -> list[ase.Atoms]`: Retrieves all atoms objects from the database that have a matching state. This is the primary method for the engines to acquire their work items.
        -   `update_with_dft_results(self, atoms_id: int, results: DFTResult)`: Updates a specific database entry (identified by its unique ID) with the results from a DFT calculation. Crucially, this method will also change the entry's `state` to `'labelled'`, signifying that the work is complete.
-   **`src/mlip_autopipec/data/models.py`:**
    -   **`DFTResult` (Pydantic Model):** A dedicated data class will be used to ensure that the data passed from the parser to the database is structured, validated, and type-safe. This prevents common errors related to incorrect data shapes or types.
        -   `energy: float`
        -   `forces: np.ndarray`
        -   `stress: np.ndarray`
-   **`src/mlip_autopipec/modules/labelling_engine.py`:**
    -   **`LabellingEngine` class:** This class will contain all the logic for automated DFT calculations.
        -   `__init__(self, db: AseDB, config: dict, runner: ProcessRunner)`: The engine will be initialised with its dependencies: the database wrapper, a configuration dictionary, and an abstraction for running external processes. This use of Dependency Injection is key to making the class testable.
        -   `run()`: The main public method that iterates over all "unlabelled" structures in the database and processes them.
        -   `_generate_qe_input(self, atoms: ase.Atoms) -> str`: A private method that constructs the content of the Quantum Espresso input file as a string. It will use helper functions from `dft_utils.py` to determine calculation parameters based on the configuration and the atomic species present.
        -   `_execute_dft(self, input_str: str) -> str`: A private method that uses the injected `ProcessRunner` to execute `pw.x`, passing the input string via standard input, and returns the standard output as a string.
        -   `_parse_qe_output(self, output_str: str) -> DFTResult`: A private method that parses the output text from Quantum Espresso to extract the required physical quantities and package them into a `DFTResult` object.
-   **`src/mlip_autopipec/modules/training_engine.py`:**
    -   **`TrainingEngine` class:** This class will encapsulate all logic related to training the MLIP.
        -   `__init__(self, db: AseDB, config: dict)`: Takes the database wrapper and configuration as dependencies.
        -   `run()`: The main public method that orchestrates the entire training process from data fetching to model saving.
        -   `_prepare_dataset(self) -> list[dict]`: Fetches the labelled data from the database and converts it into a format suitable for training.
        -   `_calculate_baseline(self, dataset: list[dict]) -> list[dict]`: A private method that calculates the energy and forces for each structure using a simple baseline potential (e.g., Lennard-Jones).
        -   `_calculate_delta(self, dataset: list[dict]) -> list[dict]`: A private method that calculates the residual between the baseline and the DFT data, which will be the actual training target.
        -   `_train_model(self, delta_dataset: list[dict])`: This private method interfaces with the chosen ACE training library to perform the model fitting and saves the final potential to a file specified in the configuration.

This design cleanly decouples the core scientific logic of each module from the specifics of the database implementation or external process execution. This abstraction is critical for enabling effective and fast unit testing.

## 4. Implementation Approach

The implementation for Cycle 01 will proceed in a logical, bottom-up manner, ensuring that each component is built upon a tested and reliable foundation before the next is added.

1.  **Project Scaffolding:** The first step is to establish the project's structure. This involves creating the `pyproject.toml` file and defining all necessary dependencies for this cycle, including `ase`, `pydantic`, `pyyaml`, `numpy`, and the chosen MLIP training library. The source directory structure (`src/mlip_autopipec`, `tests/`) will also be created. A virtual environment will be set up using `uv` to ensure a clean and reproducible development environment.
2.  **Database Wrapper (`AseDB`):** The `AseDB` class will be implemented first, as it is the central component for data flow and state management. Its methods will be thoroughly unit-tested using a temporary on-disk SQLite database to ensure they perform the correct database operations and handle data correctly. This early focus on the data layer prevents data-related issues in later stages.
3.  **Labelling Engine - I/O and Parsing:** The "pure" functions of the `LabellingEngine`—those that simply transform data—will be implemented next. This includes `_generate_qe_input` and, most importantly, `_parse_qe_output`. The parser is a critical component and will be developed and tested against a comprehensive collection of pre-saved, real Quantum Espresso output files, including examples of both successful and failed runs. This ensures the parser is robust before it is integrated into the full workflow.
4.  **Process Execution Abstraction:** A `ProcessRunner` protocol (or abstract base class) will be defined in `src/mlip_autopipec/utils/runner.py`. A concrete implementation, `SubprocessRunner`, will be created that uses Python's `subprocess` module. The `LabellingEngine` will be designed to depend on the abstract protocol, not the concrete implementation. This design is crucial for testing, as it allows unit tests for the `LabellingEngine` to inject a `MockRunner` that returns canned output, completely avoiding any actual external process calls.
5.  **Labelling Engine - Orchestration:** With the I/O, parsing, and execution components in place, the main `run()` method of the `LabellingEngine` will be implemented. This method will tie together the database access for fetching jobs, input generation, execution via the `ProcessRunner`, parsing, and saving the results back to the database.
6.  **Training Engine:** The `TrainingEngine` class will be implemented next. The initial implementation of the "Delta Learning" will use a simple Lennard-Jones potential with fixed, hardcoded parameters for a known simple system (e.g., Argon) to validate the approach. The methods for data preparation and delta calculation will be unit-tested for numerical correctness. The final `_train_model` method will initially be a straightforward wrapper around the MLIP library's main training function.
7.  **Main Orchestrator Script:** Finally, the top-level script (`run_cycle_01.py`) will be created. It will be responsible for parsing a configuration file, initialising the `AseDB`, `LabellingEngine` (with a `SubprocessRunner`), and `TrainingEngine`, and then calling their `run()` methods in the correct sequence to execute the full, linear workflow for this cycle.

## 5. Test Strategy

Testing for Cycle 01 is of paramount importance as it validates the correctness of the core scientific calculations and data processing pipeline. The strategy will be multi-layered, combining comprehensive unit tests for isolated components and a set of integration tests to verify the data flow between them.

**Unit Testing Approach (Min 300 words):**
Unit tests will form the bedrock of the quality assurance for this cycle, ensuring that each individual piece of logic is correct before it is integrated into the larger system. The `pytest` framework will be used, along with the `pytest-mock` plugin for creating mock objects.
-   **`AseDB` Wrapper:** The database wrapper will be tested against a temporary, local SQLite file created and destroyed for each test function. Tests will rigorously verify that `add_atoms` correctly creates rows in the database, that `get_atoms_by_state` retrieves the correct subset of data based on the 'state' flag, and that `update_with_dft_results` correctly modifies existing rows and changes their state as expected. Edge cases, such as an empty database or attempting to update a non-existent entry, will also be tested.
-   **`LabellingEngine`:** This class will be tested heavily using mock objects for its dependencies. The `AseDB` and `ProcessRunner` instances passed to its constructor will be `MagicMock` objects. Tests for the main `run()` method will configure the mock database to return a predefined list of "unlabelled" atoms. The test will then assert that the engine calls the (mocked) process runner and the (mocked) database update method for each atom, verifying the orchestration logic. The `_generate_qe_input` method will be tested as a pure function to ensure it produces a syntactically correct and physically sensible input file for a given `ase.Atoms` object. The `_parse_qe_output` method is critical and will be tested against a suite of static text files representing various outcomes of QE runs (e.g., successful convergence, non-convergence, crashes), ensuring it extracts numerical data correctly or raises the appropriate exceptions.
-   **`TrainingEngine`:** The data preparation and delta calculation logic will be tested with sample data structures to verify the numerical correctness of the residual calculation against hand-calculated or known results. The interaction with the actual MLIP training library will be completely mocked. For instance, the test for `_train_model` will assert that the method calls the underlying library's `train()` function with a dataset that has been correctly processed by the preceding delta calculation steps. This confirms the data is being prepared correctly without performing any actual, time-consuming model training.

**Integration Testing Approach (Min 300 words):**
Integration tests will verify the flow of data and control between the modules, ensuring they work together as intended. They will use a real, temporary database file but will still mock the most expensive external process (the DFT calculation) to keep the tests fast and reliable.
-   **Labelling -> Database:** A crucial integration test will instantiate a real `AseDB` (using a temporary file) and a `LabellingEngine`. The `LabellingEngine`'s internal process runner dependency will be mocked to return a string containing a pre-saved, valid Quantum Espresso output. The test will begin by adding an unlabelled atom to the database. It will then call `LabellingEngine.run()`. Finally, it will use the `AseDB` instance to query the database and assert that the atom's state has been correctly changed to "labelled" and that its energy, forces, and stress have been populated with the correct values from the mock output. This validates the entire labelling workflow, from database read to execution and back to database write.
-   **Database -> Training:** A second key integration test will focus on the training half of the pipeline. It will pre-populate a temporary `AseDB` with realistic "labelled" data. It will then instantiate and run the `TrainingEngine`. The test will not check the quality of the trained model but will assert that the engine successfully reads the data from the database, processes it through the delta learning scheme without errors, and produces a non-empty model file at the end of the run. This verifies that the `TrainingEngine` can correctly consume the data format produced by the `LabellingEngine`.
-   **Full Workflow (Dry Run):** A top-level integration test will run the main orchestrator script. It will use a mock process runner for the `LabellingEngine` and mock the actual training call in the `TrainingEngine`. The purpose of this test is to ensure the configuration is passed correctly through all layers and that the modules are instantiated and invoked in the right order without crashing or raising exceptions. This provides confidence that the overall application structure is sound.