# Cycle 03 Specification: High-Throughput Exploration and Sampling

## 1. Summary

This document provides the technical specifications for Cycle 03 of the MLIP-AutoPipe project. The central goal of this cycle is to dramatically enhance the efficiency and intelligence of the data generation process, marking a significant leap in the system's capabilities. While Cycle 02 automated the creation of an initial, diverse set of *static* structures, this cycle introduces a crucial *dynamic exploration* phase. This will be achieved by implementing the **Explorer & Sampler** module, a critical component that performs high-throughput exploration of the material's potential energy surface without resorting to expensive DFT calculations. This module is the key to ensuring that the final MLIP is trained not just on a wide variety of structures, but on a set of structures that is maximally informative and relevant to the material's actual behaviour under realistic conditions.

The core of this new module is the integration of a pre-trained, universal Machine Learning Interatomic Potential (in this case, **MACE (Materials Agent Chemical Environment)**) as a surrogate model. This powerful, general-purpose model, itself trained on a vast database of materials, allows the system to run extensive molecular dynamics (MD) simulations, generating trajectories containing millions of atomic configurations across a wide range of temperatures and pressures. This is achieved at a fraction of the computational cost of traditional Ab Initio Molecular Dynamics (AIMD), enabling the exploration of the system's phase space on a scale that would be otherwise intractable. From this enormous pool of candidate structures, the module will then employ an intelligent sampling algorithm, **DIRECT**, to select a small, diverse, and maximally informative subset of structures for subsequent DFT labelling. This ensures that the expensive DFT calculations are focused only on the most valuable data points.

A key secondary objective of this cycle is performance optimisation. The descriptor calculations and clustering required for the DIRECT algorithm can become a computational bottleneck when processing millions of MD frames. To address this, performance-critical sections of the Python code will be identified through profiling and then accelerated using **Numba**, a just-in-time (JIT) compiler that can translate Python and NumPy code into fast, optimised machine code comparable in speed to C or Fortran. Upon completion of this cycle, the MLIP-AutoPipe will have evolved from a pipeline that relies on a static set of initial guesses to a much more powerful system that actively and efficiently explores the potential energy surface to select the most valuable data for training its own high-fidelity model.

## 2. System Architecture

The architecture for Cycle 03 introduces the new `Explorer & Sampler` module into the workflow. This module is strategically positioned between the `StructureGenerator` and the `LabellingEngine`, transforming the pipeline from a simple sequential process into one with a dedicated, large-scale data enrichment phase.

1.  **Input:** The workflow begins as in Cycle 02. The `ConfigExpander` generates a full configuration from the user's minimal `input.yaml`, and the `StructureGenerator` uses this to create an initial set of diverse, unlabelled structures, which are saved to the ASE database.
2.  **Module B: `Explorer & Sampler`:** This new module is now invoked by the orchestrator. Its operation constitutes the main focus of this cycle.
    *   It queries the database to retrieve the initial structures created by the `StructureGenerator`.
    *   For each of these initial structures, it runs a large-scale Molecular Dynamics (MD) simulation using the pre-trained MACE potential as the force calculator. The simulation parameters (temperature, pressure, duration) are drawn from the `exec_config_dump.yaml`. The architecture will be designed to offload these calculations to a GPU if one is available, to maximise performance. These simulations will generate massive trajectory files containing millions of atomic frames.
    *   **Descriptor Calculation:** The module then processes these vast trajectories. It calculates a local structural descriptor (e.g., SOAP or ACE descriptors) for each atomic environment in each frame. This step transforms the Cartesian coordinates of the atoms into a high-dimensional vector representation that captures the local geometry. This is a performance-critical step where Numba will be applied to accelerate the calculation.
    *   **DIRECT Sampling:** The module implements the DIRECT algorithm. This involves two sub-steps. First, it performs a clustering analysis (e.g., using a fast KMeans variant) on the millions of descriptor vectors to group them into geometrically similar environments. Second, it uses stratified sampling to select a few hundred or thousand representative frames—one from each of the most populated or diverse clusters. These selected frames are the new "candidate structures" for DFT labelling.
    *   The module saves these new, high-value candidate structures back to the ASE database with the state "unlabelled". To maintain a clear data provenance and avoid re-processing, the original structures from the `StructureGenerator` that were used to seed the MD runs are updated to a new state, "explored".
3.  **`LabellingEngine`:** The `LabellingEngine`'s role and implementation remain the same as in Cycle 01. However, the data it operates on is now of much higher quality. Instead of a handful of static structures, it now retrieves the far more diverse and informative set of candidate structures produced by the `Explorer & Sampler` module. It proceeds with the DFT calculations on these structures as before.
4.  **Downstream Modules:** The `TrainingEngine` continues to operate as in previous cycles, training on the richer and more diverse dataset labelled by the `LabellingEngine`. The expectation is that the resulting MLIP will be significantly more accurate and transferable due to the superior quality of the training data.

This new architecture inserts a crucial "active exploration" step into the pipeline. This ensures that the most expensive computational resource—the time spent on DFT calculations—is reserved for structures that have been pre-screened and identified as being the most valuable for training the MLIP.

## 3. Design Architecture

The design for this cycle introduces the new `Explorer` class and creates new utility modules for descriptor calculation and performance optimisation. The design emphasises the encapsulation of complex scientific logic and the separation of performance-critical code.

-   **`src/mlip_autopipec/modules/explorer.py`:**
    -   **`Explorer` class:** This class will contain the complete logic for the exploration and sampling phase.
        -   `__init__(self, db: AseDB, config: dict)`: Initialises with the database wrapper and the full configuration dictionary, which contains a new `exploration` section.
        -   `run()`: The main public method that orchestrates the entire process: fetching initial structures, running MD for each, and then sampling the combined trajectories.
        -   `_run_mace_md(self, atoms: ase.Atoms) -> list[ase.Atoms]`: A private method that takes a single starting structure, loads the pre-trained MACE model, attaches it as an ASE calculator (explicitly moving the model to the GPU if configured and available), sets up an ASE MD simulation (e.g., using `Langevin` dynamics for NVT), and runs it for the specified number of steps. It returns the entire trajectory as a list of `ase.Atoms` objects to conserve memory.
        -   `_calculate_descriptors(self, trajectory: list[ase.Atoms]) -> np.ndarray`: A private method that iterates through the trajectory and computes descriptors for all structures. For efficiency, it will delegate the core computation to a JIT-compiled function from the `numba_kernels` module, passing NumPy arrays of positions and cell information.
        -   `_perform_direct_sampling(self, trajectory: list[ase.Atoms], descriptors: np.ndarray) -> list[ase.Atoms]`: A private method that implements the DIRECT clustering and sampling logic. It will use a fast clustering algorithm from a library like `scikit-learn-extra` (e.g., `KMedoids`) and then implement the stratified sampling logic to select the final candidate structures.
-   **`src/mlip_autopipec/utils/numba_kernels.py`:**
    -   This new file will be created to house performance-critical functions that are to be accelerated with Numba. The functions will be decorated with `@jit(nopython=True, fastmath=True, parallel=True)`.
    -   **`calculate_soap_descriptors_fast(...)`:** A JIT-compiled function for calculating SOAP descriptors. It will contain the explicit, low-level loops over atoms and their neighbours, operations that are typically very slow in pure Python but can be heavily optimised and parallelised by Numba. This design cleanly isolates the highly optimised, numerically-intensive code from the higher-level application logic.
-   **`src/mlip_autopipec/config/expander.py`:**
    -   The `ConfigExpander` will be updated to populate a new `exploration` section in the `exec_config_dump.yaml`. This will include parameters that the user can optionally specify in `input.yaml`, such as the MD simulation temperatures, the number of MD steps, the number of structures to select via DIRECT, and the type of descriptor to use. The heuristic engine will provide sensible defaults for all of these.
-   **`pyproject.toml`:**
    -   New dependencies will be added to the project definition: `mace-torch` (to provide the MACE model and its PyTorch backend), `numba` (for the JIT compilation), and potentially a library for fast clustering like `scikit-learn-extra`.

The design ensures that the complex scientific logic of the exploration and sampling process is encapsulated within the `Explorer` class, while the highly optimised numerical code is cleanly separated into the `numba_kernels` module for maintainability and clarity.

## 4. Implementation Approach

The implementation of Cycle 03 will be tackled in a sequence that addresses the main technical challenges incrementally.

1.  **Dependency Setup:** The first step is to add `mace-torch` and `numba` to the `pyproject.toml` file. A crucial part of this step is to verify the installation in a clean virtual environment, as `mace-torch` has a complex set of dependencies, including a specific version of PyTorch. The correct installation will be confirmed by importing the libraries in a Python shell.
2.  **MACE MD Simulation:**
    *   Development will begin with the implementation of the `_run_mace_md` method in the `Explorer` class. This involves learning the `mace-torch` API for loading the pre-trained model and attaching it as a calculator to an `ase.Atoms` object. The logic for automatically detecting and using a GPU will be implemented here.
    *   A small, standalone script will be written to test this functionality independently. This script will run a short MD simulation for a simple system (e.g., bulk silicon) and save the trajectory, which will be visually inspected to verify that the MACE potential is producing stable dynamics.
3.  **Descriptor Calculation (Pure Python First):**
    *   To ensure correctness before optimising, a pure Python version of the descriptor calculation logic will be implemented first, likely within the `Explorer` class itself. This allows for easier debugging and step-by-step verification of the algorithm's logic. An existing, trusted library for SOAP/ACE descriptors (e.g., `dscribe`) will be used as a reference.
4.  **Performance Optimisation with Numba:**
    *   Once the pure Python implementation is verified, the code will be profiled to identify the key loops (e.g., iterating over atoms and neighbours) that are the performance bottleneck.
    *   This performance-critical logic will be moved into a separate function in `numba_kernels.py` and the `@jit` decorator will be applied. The function signature will be carefully designed to work with simple NumPy arrays for maximum compatibility with Numba.
    *   The `_calculate_descriptors` method in the `Explorer` will be refactored to call this new, fast JIT-compiled function. Performance benchmarks will be run to quantify the speed-up.
5.  **DIRECT Sampling:** The `_perform_direct_sampling` method will be implemented. This will involve using a standard, fast clustering algorithm on the descriptor data, followed by a stratified sampling logic to pick representatives from each cluster. The number of clusters and samples will be controlled by parameters from the configuration file.
6.  **Integration and Orchestration:**
    *   The main `run()` method of the `Explorer` class will be implemented, tying all the private methods together into a coherent workflow.
    -   The main orchestrator script will be updated to instantiate and run the `Explorer` module at the correct point in the pipeline (after the `StructureGenerator` and before the `LabellingEngine`).
    -   The new `exploration` section of the configuration file will be fully integrated and its parameters will be passed down to the `Explorer` to control its behaviour.

## 5. Test Strategy

Testing for Cycle 03 will focus on the correctness of the MD simulation setup, the numerical accuracy of the optimised descriptor calculations, and the effectiveness of the sampling algorithm in selecting a diverse dataset.

**Unit Testing Approach (Min 300 words):**
-   **`Explorer`:** The `Explorer` class will be unit-tested by mocking its most complex and time-consuming dependencies. The call to the ASE MD simulation runner will be mocked to avoid long-running calculations. The test for `_run_mace_md` will focus on verifying that the method correctly loads the MACE model (which will be a mock object), attaches it as a calculator, and correctly sets up the ASE dynamics object with the temperatures and timesteps taken from the configuration file. For the sampling logic, the `_perform_direct_sampling` method will be tested with a pre-calculated, simple 2D NumPy array representing a set of descriptors. The test will assert that the method returns the correct number of structures and that they are a representative subset (e.g., one from each of several predefined clusters), thus verifying the selection logic.
-   **`numba_kernels`:** The JIT-compiled functions are pure numerical functions and are ideal for unit testing. The `calculate_soap_descriptors_fast` function will be tested for numerical correctness by comparing its output against a trusted reference implementation (e.g., from the `dscribe` library). The test will create a simple `ase.Atoms` object, run both our Numba-accelerated function and the reference implementation on it, and then assert that the resulting descriptor vectors are numerically identical to within a very small tolerance (e.g., 1e-6). This is a critical test to ensure that the performance optimisation has not introduced any subtle bugs in the scientific calculation.

**Integration Testing Approach (Min 300 words):**
-   **MACE API Integration:** A key integration test will verify the live interaction with the `mace-torch` library. This test will load the actual pre-trained MACE model from disk, attach it to a simple `ase.Atoms` object (e.g., a water molecule), and request a single-point energy and force calculation. The test will assert that the returned values are of the correct type and shape (`float` for energy, `np.ndarray` for forces) and are numerically plausible. This test does not run a long simulation, but it validates that our development environment is set up correctly and that our code is using the MACE API as intended.
-   **Explorer -> DB:** An integration test will verify the flow of data from the `Explorer` module to the database. It will start with a single initial structure in a temporary `AseDB`. It will then run the `Explorer.run()` method. To keep the test fast, the MD simulation will be configured to run for only a few steps. The test will then connect to the database and assert that a new set of "unlabelled" candidate structures has been created, and that the original seeding structure has had its state correctly updated to "explored". This test validates the entire data lifecycle within the module.
-   **Full Workflow Smoke Test:** The smoke test from Cycle 02 will be extended to include the new module. It will now run the full `ConfigExpander` -> `StructureGenerator` -> `Explorer` -> `LabellingEngine` -> `TrainingEngine` workflow. All long-running or external processes (MD, DFT, Training) will be heavily mocked or configured to be trivial (e.g., MD runs for one step). The test will verify that the five modules can be chained together in the correct sequence, passing configuration and data correctly, without crashing. This is a crucial sanity check of the overall application integration.