# Cycle 03 Specification: High-Throughput Exploration and Optimisation

**Version:** 1.0.0
**Status:** Final
**Cycle Goal:** To dramatically improve the efficiency and effectiveness of the data generation process by implementing a surrogate-based exploration and sampling module (Module B) and optimising its performance-critical components.

## 1. Summary

Cycle 03 marks a pivotal transition from a simple, linear generation process to a sophisticated, efficiency-driven workflow. The core objective is to integrate **Module B: The Explorer & Sampler**, a component designed to intelligently explore a vast range of atomic configurations at a tiny fraction of the cost of DFT calculations. This cycle directly addresses the challenge of finding the most "informative" structures to label, ensuring that our limited budget of expensive DFT calculations is spent as wisely as possible. We will achieve this by leveraging pre-trained, universal foundation models (such as MACE-MP or M3GNet), which act as low-cost surrogates for DFT.

The new workflow will begin by taking the initial, physically-plausible structures generated by Module A and using them as starting points for large-scale Molecular Dynamics (MD) simulations. These simulations will be powered by the fast surrogate potential, allowing us to generate massive trajectories containing millions of candidate structures, covering a wide range of temperatures and pressures. The central challenge then becomes selecting a small, diverse, and representative subset from this enormous pool of candidates. To solve this, we will implement the **DIRECT (Dimensionality-reduction-based Iterative Representative-point selection for Cluster-based stratified-sampling)** sampling strategy. This involves computing a structural descriptor (e.g., SOAP) for each candidate, using dimensionality reduction techniques like UMAP to visualise the conformational space, and then applying stratified sampling to pick structures that cover this space comprehensively.

A crucial aspect of this cycle is performance. The sheer volume of data being processed by Module B—millions of structures and their corresponding high-dimensional descriptors—presents a significant computational bottleneck. To ensure the pipeline remains fast and responsive, we will proactively identify these bottlenecks and rewrite them using **Numba**, a high-performance, just-in-time (JIT) compiler. This will transform critical Python loops in our descriptor calculation and clustering algorithms into highly optimised machine code, achieving performance comparable to C or Fortran. By the end of this cycle, the MLIP-AutoPipe will be capable of generating far superior training datasets than before, leading to more accurate and robust potentials with significantly fewer DFT calculations.

## 2. System Architecture

The architecture in Cycle 03 introduces Module B as a new, distinct stage in the pipeline, positioned between Module A (Structure Generation) and Module C (Labelling Engine). The Orchestrator's logic will be updated to manage this new data processing and selection step.

**Component Breakdown:**

*   **Module B: Explorer & Sampler (`modules/b_explorer_sampler.py`):** This is the central component of this cycle. It will be implemented as a class, `Explorer`, which encapsulates the entire exploration and sampling workflow.
    *   **Surrogate MD Simulation:** The module will be configured to use a specific pre-trained universal potential (the model will be downloaded on-demand and cached). It will take the initial structures from Module A and run MD simulations using an engine like ASE's VelocityVerlet, powered by the surrogate model. This will generate the raw trajectory files.
    *   **Descriptor Calculation:** It will process the trajectory, and for each frame, it will calculate a local structural descriptor for each atom. The primary choice will be SOAP (Smooth Overlap of Atomic Positions). This step is computationally intensive and a prime candidate for optimisation.
    *   **Dimensionality Reduction:** The high-dimensional descriptor data will be projected down to a 2D or 3D space using an algorithm like UMAP (Uniform Manifold Approximation and Projection). This allows for efficient clustering and visualisation.
    *   **Stratified Sampling:** The low-dimensional data points will be clustered (e.g., using a simple grid-based or k-means approach). The sampling logic will then select a fixed number of representative points from each cluster, ensuring that both highly populated (stable) and sparsely populated (transitional) regions of the conformational space are represented in the final dataset.

*   **Performance Optimisation Utility (`utils/performance.py`):** A new module will be created to house performance-critical functions that have been optimised with Numba.
    *   **`fast_soap_kernels`:** This will contain JIT-compiled functions for calculating SOAP descriptors. While we may use an existing library like `dscribe`, if customisation or performance becomes an issue, we will implement our own optimised kernels here.
    *   **`parallel_descriptor_compute`:** A function that uses Numba's `prange` for parallel execution to compute descriptors for an entire trajectory across multiple CPU cores.

*   **Orchestrator (`orchestrator.py`):** The orchestrator's workflow will be significantly updated:
    1.  (From Cycle 2) Generate initial structures with Module A.
    2.  **New:** Instantiate and run `Explorer` (Module B) with these initial structures.
    3.  The `Explorer` will return a smaller, highly informative list of ASE `Atoms` objects.
    4.  (From Cycle 1) Pass this new, curated list of structures to the Labelling Engine (Module C).
    5.  Proceed with training on this high-quality dataset.

This new architecture inserts a crucial "filtering" step that dramatically increases the quality of the data reaching the expensive DFT stage, optimising the use of computational resources.

## 3. Design Architecture

The design for Cycle 03 focuses on building a modular and performant `Explorer` class, with clear separation between the simulation, analysis, and sampling stages.

**Key Classes and APIs:**

*   **`mlip_pipe.modules.b_explorer_sampler.Explorer`**
    *   `__init__(self, config)`: Initializes with a configuration object specifying the surrogate model, MD parameters (temperature, pressure), and sampling settings.
    *   `explore_and_sample(self, initial_structures: list[ase.Atoms]) -> list[ase.Atoms]`: The main public method. It takes the output of Module A and returns the final, sampled list of structures for Module C.
    *   `_run_surrogate_md(self, structure: ase.Atoms) -> ase.io.Trajectory`: Internal method to run a single MD simulation for one starting structure.
    *   `_calculate_descriptors(self, trajectory: ase.io.Trajectory) -> np.ndarray`: Internal method that calls the optimised functions in `utils.performance` to compute descriptors for all frames in a trajectory.
    *   `_get_representative_samples(self, descriptors: np.ndarray) -> list[int]`: Internal method that implements the UMAP projection and stratified sampling logic to return the indices of the frames to be selected for DFT labelling.

*   **`mlip_pipe.utils.performance`**
    *   `@numba.jit(nopython=True, parallel=True)`
        `compute_soap_for_trajectory(...) -> np.ndarray`: A high-performance function decorated with Numba's JIT compiler. It will contain the core loops for descriptor calculation, parallelised over the atoms or frames. This is where the main performance-critical code will live.

*   **Configuration (`exec_config_dump.yaml`)**
    *   A new section, `explorer`, will be added to the configuration schema. It will contain sub-sections for `surrogate_model` (e.g., "MACE-MP"), `md_settings` (e.g., `temperature_K`, `n_steps`), and `sampler_settings` (e.g., `n_samples_to_select`, `descriptor_type`). The `ConfigExpander` will be updated to populate this section with sensible defaults.

## 4. Implementation Approach

The implementation will focus on building Module B first, optimising it, and then integrating it into the main workflow.

1.  **Surrogate Integration:**
    *   Begin by selecting a universal potential library (e.g., `mace-torch`). Implement the logic to load the pre-trained model and attach it as an ASE calculator to an `Atoms` object.
    *   Write a simple script to run a short MD simulation using this calculator to verify that the integration is working correctly.

2.  **Implement the Explorer Class:**
    *   Develop the `Explorer` class and its internal methods.
    *   First, implement a pure Python, non-optimised version of the descriptor calculation and sampling workflow. This allows for rapid prototyping and correctness checking. The initial version can use a library like `dscribe` for SOAP calculation and `scikit-learn` for UMAP and clustering.

3.  **Profiling and Optimisation:**
    *   Create a benchmark test case: a large trajectory file (e.g., 100,000 frames).
    *   Profile the `_calculate_descriptors` method. Use profiling tools to identify the exact lines of code that are the performance bottlenecks (likely the loops inside the descriptor calculation).
    *   Create the `utils.performance` module.
    *   Translate the bottleneck Python code into a new function in this module. Apply the `@numba.jit` decorator and refactor the code as needed to make it compatible with Numba's `nopython` mode (e.g., using only basic NumPy operations and loops).
    *   Use Numba's `prange` to enable automatic parallelisation.
    *   Re-run the benchmark to quantify the speed-up, aiming for at least a 10x improvement over the pure Python version.

4.  **Integration with Orchestrator:**
    *   Update the `FullConfig` Pydantic model to include the new `explorer` section.
    *   Update the `ConfigExpander` to add default values for these new settings.
    *   Modify the `Orchestrator` to instantiate and call the `Explorer` class at the correct point in the pipeline, passing its output to the `QuantumEspressoRunner`.

5.  **End-to-End Testing:**
    *   Create a new integration test that runs the full Cycle 3 pipeline. This test will be slower than previous ones, so it should use a small system and short MD runs.
    *   The test will start from `input.yaml` and verify that Module A, Module B, Module C, and Module D are all executed in the correct sequence.
    *   The key assertion will be to check the number of structures: the number of structures passed from Module B to Module C should be significantly smaller than the total number of frames in the MD trajectory, proving that the sampling step is working.

## 5. Test Strategy

Testing for Cycle 03 focuses on the correctness of the complex sampling algorithm and validating the significant performance improvements from optimisation.

**Unit Testing Approach (Min 300 words):**
*   **`TestExplorer`:** The `Explorer`'s methods will be tested individually.
    *   The MD simulation part will be tested by running a very short simulation (e.g., 10 steps) and asserting that a trajectory file is created and has the correct number of frames.
    *   The sampling logic in `_get_representative_samples` is the most critical part to test. We will create a static, pre-computed descriptor array representing a known distribution (e.g., two distinct clusters). We will run the sampling method on this fixed input and assert that it selects the correct number of samples, and that the selected samples are drawn from both clusters, proving the stratified approach is working. We will test edge cases, like requesting more samples than available frames.
*   **`TestPerformanceUtils`:** This suite will focus on correctness and performance.
    *   **Correctness:** We will implement a "slow but simple" pure Python version of our descriptor calculation. The unit test will compute descriptors for a small structure using both the Numba-optimised version and the pure Python version and assert that the results are numerically very close (within a small tolerance). This guarantees that our optimisations have not introduced bugs.
    *   **Performance:** We will create a dedicated benchmark test (e.g., marked with `pytest.mark.benchmark`). This test will run the optimised function on a large, realistic dataset and assert that its execution time is below a certain threshold. This test will fail if a future code change causes a performance regression, automatically guarding our optimisations.

**Integration Testing Approach (Min 300 words):**
The main integration test will verify the new end-to-end workflow and the data handoff between the modules.

*   **`test_pipeline_with_explorer`:**
    1.  **Setup:** Start with a minimal `input.yaml` for a system like Carbon.
    2.  **Execution:** Run the full orchestrator.
    3.  **Process & Assertions:**
        *   The test will trace the execution flow. It will first assert that `Module A` is called and generates a small number of initial diamond structures.
        *   Then, it will assert that `Module B` (`Explorer`) is called. Inside the test, we can configure the MD to run for a specific number of steps (e.g., 100 steps).
        *   The crucial assertion: We will check the number of structures returned by the `Explorer`. If the sampling is configured to select 10 structures, we will assert that the input to `Module C` is a list of exactly 10 `Atoms` objects. This proves the sampling filter is working as intended.
        *   Finally, the test will let the pipeline complete, running DFT on the 10 sampled structures and training a final potential, asserting that a potential file is created.

This test provides confidence that Module B is not just working in isolation but is correctly integrated into the larger pipeline, taking input from Module A and providing correctly formatted output to Module C, thereby achieving the cycle's primary goal of efficient, targeted data selection.